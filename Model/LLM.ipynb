{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0d931724f0d45dcac5b331a4100866a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_858d3c2bc3a44b34b8e98a9cc721b7fe",
              "IPY_MODEL_7b3009b54bb14bd9a178c63753cd369d",
              "IPY_MODEL_2a0659fc8707449e8770260984c7a027"
            ],
            "layout": "IPY_MODEL_5b4eef491ad849d598a2298d34b40c05"
          }
        },
        "858d3c2bc3a44b34b8e98a9cc721b7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd1529df12441bcb2eb1a4d1ae13bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_977d4870c7fa4654b9fa2b721f5644b7",
            "value": "Map: 100%"
          }
        },
        "7b3009b54bb14bd9a178c63753cd369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867e6063bbeb495dbfda8f5e44745d8f",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0118e387c170401ba6456f8f70cbf14e",
            "value": 42
          }
        },
        "2a0659fc8707449e8770260984c7a027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1540ee157c6141e78ea9fc978fc6c6da",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc47b6fb7fa44c186915bf8deed24e5",
            "value": " 42/42 [00:00&lt;00:00, 297.25 examples/s]"
          }
        },
        "5b4eef491ad849d598a2298d34b40c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd1529df12441bcb2eb1a4d1ae13bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977d4870c7fa4654b9fa2b721f5644b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867e6063bbeb495dbfda8f5e44745d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0118e387c170401ba6456f8f70cbf14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1540ee157c6141e78ea9fc978fc6c6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc47b6fb7fa44c186915bf8deed24e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa2e95f242f47cdafa8cfee05de772c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde7f1577aab4b3bbe1e9e867d5a8509",
              "IPY_MODEL_8c659a114d274933861f03ebfb058582",
              "IPY_MODEL_3983fee686624f6cb9b4a81893b2c966"
            ],
            "layout": "IPY_MODEL_797cd07a57eb426398a0cdeb17ba53b5"
          }
        },
        "fde7f1577aab4b3bbe1e9e867d5a8509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357944f4a3134f088aa1a0e558d93998",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3bb05d1d344bbea7f605c0b04753eb",
            "value": "Map: 100%"
          }
        },
        "8c659a114d274933861f03ebfb058582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3e1b51eb9b4634a12351786530cdab",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f77d5f165b89444b80c7d5ee70651db1",
            "value": 3
          }
        },
        "3983fee686624f6cb9b4a81893b2c966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a470a9ba82984c618dfdd36d1e9750c6",
            "placeholder": "​",
            "style": "IPY_MODEL_53930c6640f14fe2a6b39b90c97d75d9",
            "value": " 3/3 [00:00&lt;00:00, 54.95 examples/s]"
          }
        },
        "797cd07a57eb426398a0cdeb17ba53b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357944f4a3134f088aa1a0e558d93998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3bb05d1d344bbea7f605c0b04753eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b3e1b51eb9b4634a12351786530cdab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77d5f165b89444b80c7d5ee70651db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a470a9ba82984c618dfdd36d1e9750c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53930c6640f14fe2a6b39b90c97d75d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# End-to-end: Fine-tune Flan-T5 with LoRA on CSV → Agentic RAG\n",
        "# ============================================================\n",
        "# Install dependencies (run once)\n",
        "!pip install -q transformers datasets peft accelerate sentencepiece \\\n",
        "             langchain langchain-community langgraph faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX9Ie5ryHa48",
        "outputId": "9c4096a6-69e9-4ade-ec70-f1421ad1155a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/2.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 0. Imports & basic config\n",
        "# -------------------------\n",
        "import os, random, math, json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    TrainingArguments, Trainer, DataCollatorForSeq2Seq, pipeline\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# For embeddings + vector DB\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "# LangChain / LangGraph for agentic flow\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict"
      ],
      "metadata": {
        "id": "HrDSd1m5HWkV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Config - change as needed\n",
        "# -------------------------\n",
        "CSV_PATH = \"/content/Cleaned Dataset w-o code.csv\"   # <--- adjust if different\n",
        "FINETUNE_DIR = \"./finetuned_flan_csv\"\n",
        "EPOCHS = 5\n",
        "BS = 4                      # per device batch size (reduce for low VRAM)\n",
        "LR = 3e-4\n",
        "MAX_INPUT_LEN = 192\n",
        "MAX_TARGET_LEN = 128\n",
        "LORA_R = 8\n",
        "SEED = 42\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.makedirs(FINETUNE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "-zcebhHJHZKm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 1) Load & prepare CSV\n",
        "# -------------------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Loaded CSV shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Pick input/output columns automatically:\n",
        "# - prefer columns named 'input' and 'output'\n",
        "# - else use first col as input and last col as target\n",
        "if {\"input\", \"output\"}.issubset(df.columns):\n",
        "    inp_col, out_col = \"input\", \"output\"\n",
        "elif df.shape[1] >= 2:\n",
        "    inp_col, out_col = df.columns[0], df.columns[-1]\n",
        "else:\n",
        "    raise ValueError(\"CSV must have at least 2 columns (input & target).\")\n",
        "\n",
        "# Fill NaNs and cast to strings to avoid Arrow errors\n",
        "df = df[[inp_col, out_col]].fillna(\"\").astype(str)\n",
        "df = df.rename(columns={inp_col: \"input_text\", out_col: \"target_text\"})\n",
        "print(\"Using columns:\", \"input_text -> target_text\")\n",
        "display(df.head(3))\n",
        "\n",
        "# Create simple instruction-style prompt template for fine-tuning:\n",
        "def make_pair(inp, tgt):\n",
        "    # adapt template to your task; keep concise so the model focuses on content\n",
        "    prompt = f\"Instruction: Answer the question based on the CSV row data.\\nInput: {inp}\\n\\nAnswer:\"\n",
        "    return prompt, tgt\n",
        "\n",
        "pairs = [make_pair(i, t) for i, t in zip(df[\"input_text\"], df[\"target_text\"])]\n",
        "train_df = pd.DataFrame(pairs, columns=[\"input_text\", \"target_text\"])\n",
        "\n",
        "# small train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_pd, test_pd = train_test_split(train_df, test_size=0.06, random_state=SEED)\n",
        "hf_dset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_pd.reset_index(drop=True)),\n",
        "    \"test\": Dataset.from_pandas(test_pd.reset_index(drop=True))\n",
        "})\n",
        "print(\"Train/test sizes:\", len(hf_dset[\"train\"]), len(hf_dset[\"test\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "mLTRcivjBSwo",
        "outputId": "6e3afb3b-f08e-4b3a-9906-1508e7730ccc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CSV shape: (45, 13)\n",
            "Columns: ['case_number', 'date', 'time', 'mine', 'owner', 'district', 'state', 'code', 'cause', 'fatalities', 'persons', 'narrative', 'summary']\n",
            "Using columns: input_text -> target_text\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  input_text                                        target_text\n",
              "0             On 16 May 2015 at Khetri Copper Mine (Jhunjhun...\n",
              "1        2.0  On 28 November 2015 at Kayad Underground Mine ...\n",
              "2        3.0  On 14 January 2015 at Chikla Manganese Mine (B..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9daf5912-0668-4804-af40-b1edc5eb4386\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>On 16 May 2015 at Khetri Copper Mine (Jhunjhun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>On 28 November 2015 at Kayad Underground Mine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>On 14 January 2015 at Chikla Manganese Mine (B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9daf5912-0668-4804-af40-b1edc5eb4386')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9daf5912-0668-4804-af40-b1edc5eb4386 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9daf5912-0668-4804-af40-b1edc5eb4386');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5bc5343d-890d-4ad5-997c-8a38d710cd60\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bc5343d-890d-4ad5-997c-8a38d710cd60')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5bc5343d-890d-4ad5-997c-8a38d710cd60 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Train/test sizes:\\\", len(hf_dset[\\\"train\\\"]), len(hf_dset[\\\"test\\\"]))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"input_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\",\n          \"2.0\",\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"On 16 May 2015 at Khetri Copper Mine (Jhunjhunu, Rajasthan), a Driller, Vijendra Singh (32 M), was fatally injured by a fall of roof. The incident occurred when a mass of stone fell from an unsupported roof while he was connecting a compressed air hose. The accident was in contravention of Regulation 112(2)(C) of the Metalliferous Mines Regulations, 1961.\",\n          \"On 28 November 2015 at Kayad Underground Mine (Ajmer, Rajasthan), a General Mazdoor, Nana Lal Mali (24 M), was fatally injured by a fall of roof. The incident occurred when a mass of rock broke from the roof and fell onto the scissor lift platform where he was working. The accident could have been averted if the roof had been properly examined per Regulation 116(3)(b) and 47(2)(a) of the Metalliferous Mines Regulations, 1961.\",\n          \"On 14 January 2015 at Chikla Manganese Mine (Bhandara, Maharashtra), a Piece Rated Worker, Saras Hariram (43 M), was fatally injured by a fall of side. A large rock mass parted from the hanging wall and fell on him while blasted muck was being removed. The accident could have been averted if the stope had been secured as required by Regulation 112 of the Metalliferous Mines Regulations 1961.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/test sizes: 42 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 2) Tokenizer & tokenization\n",
        "# -------------------------\n",
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "# ensure pad token exists\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({\"pad_token\":\"<|pad|>\"})\n",
        "\n",
        "def preprocess(batch):\n",
        "    inputs = tokenizer(batch[\"input_text\"], truncation=True, padding=\"max_length\", max_length=MAX_INPUT_LEN)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"target_text\"], truncation=True, padding=\"max_length\", max_length=MAX_TARGET_LEN)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized = hf_dset.map(preprocess, batched=True, remove_columns=hf_dset[\"train\"].column_names)\n",
        "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "print(\"Sample tokenized batch:\", {k: v.shape for k,v in tokenized[\"train\"][0].items() if hasattr(v,'shape')})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "a0d931724f0d45dcac5b331a4100866a",
            "858d3c2bc3a44b34b8e98a9cc721b7fe",
            "7b3009b54bb14bd9a178c63753cd369d",
            "2a0659fc8707449e8770260984c7a027",
            "5b4eef491ad849d598a2298d34b40c05",
            "ebd1529df12441bcb2eb1a4d1ae13bc0",
            "977d4870c7fa4654b9fa2b721f5644b7",
            "867e6063bbeb495dbfda8f5e44745d8f",
            "0118e387c170401ba6456f8f70cbf14e",
            "1540ee157c6141e78ea9fc978fc6c6da",
            "fdc47b6fb7fa44c186915bf8deed24e5",
            "3aa2e95f242f47cdafa8cfee05de772c",
            "fde7f1577aab4b3bbe1e9e867d5a8509",
            "8c659a114d274933861f03ebfb058582",
            "3983fee686624f6cb9b4a81893b2c966",
            "797cd07a57eb426398a0cdeb17ba53b5",
            "357944f4a3134f088aa1a0e558d93998",
            "fd3bb05d1d344bbea7f605c0b04753eb",
            "9b3e1b51eb9b4634a12351786530cdab",
            "f77d5f165b89444b80c7d5ee70651db1",
            "a470a9ba82984c618dfdd36d1e9750c6",
            "53930c6640f14fe2a6b39b90c97d75d9"
          ]
        },
        "id": "GXST66kIBVhV",
        "outputId": "e2a7d8b0-1351-464f-bf2b-e20a6e348e57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0d931724f0d45dcac5b331a4100866a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aa2e95f242f47cdafa8cfee05de772c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample tokenized batch: {'input_ids': torch.Size([192]), 'attention_mask': torch.Size([192]), 'labels': torch.Size([128])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 3) Load model & apply LoRA (PEFT)\n",
        "# -------------------------\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "# resize token embeddings if tokenizer added tokens\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q\", \"v\"],   # reasonable default for T5-style attention\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model = model.to(device)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4wkXJGABXh1",
        "outputId": "21c5d01f-c29e-499c-96c5-382b6faf17a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 884,736 || all params: 248,419,584 || trainable%: 0.3561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4) TrainingArguments & Trainer\n",
        "# -------------------------\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=FINETUNE_DIR,\n",
        "    per_device_train_batch_size=BS,\n",
        "    per_device_eval_batch_size=BS,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LR,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "FgPbrQCgBbtS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 5) Fine-tune\n",
        "# -------------------------\n",
        "print(\"Starting fine-tuning... (this can take time)\")\n",
        "trainer.train()\n",
        "print(\"Training finished. Saving...\")\n",
        "model.save_pretrained(FINETUNE_DIR)\n",
        "tokenizer.save_pretrained(FINETUNE_DIR)\n",
        "print(\"Saved fine-tuned model at\", FINETUNE_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "vXeTnluMBffC",
        "outputId": "2ed79f82-3940-4f26-c928-e6245c3b8722"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning... (this can take time)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 12:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>16.103046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>14.279370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>13.090337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>12.413056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>10.066200</td>\n",
              "      <td>12.146858</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished. Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved fine-tuned model at ./finetuned_flan_csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# ✅ 6) Quick Evaluation of Fine-Tuned Flan-T5 (LoRA)\n",
        "# ======================================================\n",
        "\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n",
        "\n",
        "BASE = \"google/flan-t5-base\"\n",
        "ADAPTER_DIR = \"./finetuned_flan_csv\"   # folder with your LoRA adapter + tokenizer\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# ✅ Load tokenizer from adapter folder (includes pad token from training)\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR, use_fast=True)\n",
        "\n",
        "# ✅ Load base model and resize embeddings to match adapter tokenizer\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE)\n",
        "base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# ✅ Attach the LoRA adapter weights\n",
        "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
        "\n",
        "# ✅ Create a text2text-generation pipeline\n",
        "gen_pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        ")\n",
        "\n",
        "print(\"✅ Model & pipeline loaded successfully.\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Simple evaluation: generate predictions on test samples\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def gen_from_input(inp: str) -> str:\n",
        "    \"\"\"Generate model prediction for one input string.\"\"\"\n",
        "    prompt = (\n",
        "        f\"Instruction: Answer the question based on the CSV row data.\\n\"\n",
        "        f\"Input: {inp}\\n\\nAnswer:\"\n",
        "    )\n",
        "    out = gen_pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=128,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.3,\n",
        "        do_sample=False,\n",
        "    )[0][\"generated_text\"]\n",
        "    return out.strip()\n",
        "\n",
        "# Sample a few test examples from your held-out test set (from Section 5)\n",
        "test_samples = test_pd.sample(min(20, len(test_pd)), random_state=SEED)\n",
        "\n",
        "matches = 0\n",
        "for i, row in test_samples.iterrows():\n",
        "    inp = row[\"input_text\"]\n",
        "    tgt = row[\"target_text\"]\n",
        "    pred = gen_from_input(inp)\n",
        "    print(f\"\\n🔹 Example {i+1}\")\n",
        "    print(f\"Input: {inp[:150]}...\")\n",
        "    print(f\"Target: {tgt}\")\n",
        "    print(f\"Prediction: {pred}\")\n",
        "    if tgt.lower() in pred.lower():\n",
        "        matches += 1\n",
        "\n",
        "print(f\"\\n✅ Simple containment accuracy: {matches}/{len(test_samples)} \"\n",
        "      f\"= {matches/len(test_samples):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8LQiC2BhYc",
        "outputId": "80928c21-5d31-4386-e45a-72a2f24d6cef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model & pipeline loaded successfully.\n",
            "\n",
            "🔹 Example 40\n",
            "Input: Instruction: Answer the question based on the CSV row data.\n",
            "Input: 40.0\n",
            "\n",
            "Answer:...\n",
            "Target: On 16 August 2015 at Tripura Drilling Mine (West Tripura, Tripura), a Dy.S.Engineer, Deb Das Chkraborty (58 M), was fatally injured when an 81kg diving board extension fell 26m. The accident occurred during drill pipe operations and was in contravention of OMR, 1984 regulations 23(3) and 25(3).\n",
            "Prediction: 0\n",
            "\n",
            "🔹 Example 26\n",
            "Input: Instruction: Answer the question based on the CSV row data.\n",
            "Input: 26.0\n",
            "\n",
            "Answer:...\n",
            "Target: On 25 June 2015 at Billi Markundi Stone Mine (Sonebhadra, Uttar Pradesh), a Contract Labour, Nisha Kumari (19 F), was instantly killed when her scarf got entangled in an unguarded compressor belt-drive. The accident contravened Regulation 174(2) & (5) of the Metalliferous Mines Regulations, 1961, as the moving parts were not fenced.\n",
            "Prediction: \n",
            "\n",
            "🔹 Example 27\n",
            "Input: Instruction: Answer the question based on the CSV row data.\n",
            "Input: 27.0\n",
            "\n",
            "Answer:...\n",
            "Target: On 05 October 2015 at Jhanjhar Marble Mine (Rajsamand, Rajasthan), a Mine Mazdoor, Ramlal Meena (29 M), was fatally electrocuted while attempting to repair a live cable. The accident occurred because a non-designated person was deployed and power was not disconnected, in contravention of Central Electricity Authority Regulations, 2010.\n",
            "Prediction: \n",
            "\n",
            "✅ Simple containment accuracy: 0/3 = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Sections 7, 8 and 9 (full)\n",
        "# ===========================\n",
        "import os, json, re\n",
        "from typing import TypedDict\n",
        "import faiss\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from transformers import pipeline\n",
        "\n",
        "# ---- Assumptions: these exist from previous steps ----\n",
        "# df         : pandas.DataFrame with your CSV rows\n",
        "# gen_pipe   : pipeline(\"text2text-generation\", model=..., tokenizer=..., device=...)\n",
        "# FINETUNE_DIR: path to save artifacts (string)\n",
        "# If any of these are missing, set them appropriately before running.\n",
        "\n",
        "if \"df\" not in globals():\n",
        "    raise RuntimeError(\"df (DataFrame) not found in globals. Load your CSV into df before running this cell.\")\n",
        "if \"gen_pipe\" not in globals():\n",
        "    raise RuntimeError(\"gen_pipe not found. Ensure you created the generation pipeline in Section 6.\")\n",
        "\n",
        "os.makedirs(FINETUNE_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# 7) Build FAISS vector store\n",
        "# -------------------------\n",
        "def row_to_text(row):\n",
        "    # convert a pandas Series (row) to a single string\n",
        "    return \" | \".join([f\"{col}: {row[col]}\" for col in row.index.tolist()])\n",
        "\n",
        "docs = [row_to_text(row) for _, row in df.iterrows()]\n",
        "print(f\"Prepared {len(docs)} documents for FAISS.\")\n",
        "\n",
        "# Use sentence-transformers mini model for embeddings (small & fast)\n",
        "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedder = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "# Build LangChain FAISS vectorstore (wraps a faiss index internally)\n",
        "lc_faiss = FAISS.from_texts(docs, embedding=embedder)\n",
        "print(\"✅ FAISS vectorstore built (LangChain wrapper).\")\n",
        "\n",
        "# For optional raw faiss index saving later, access lc_faiss.index\n",
        "try:\n",
        "    raw_index = lc_faiss.index\n",
        "except AttributeError:\n",
        "    raw_index = None\n",
        "    print(\"⚠️ Could not find raw index attribute on lc_faiss (may be implementation-specific).\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A704LRfeFPoe",
        "outputId": "de226243-8d25-4c0b-e645-8f23c183434d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 45 documents for FAISS.\n",
            "✅ FAISS vectorstore built (LangChain wrapper).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 8) Build LangGraph Agentic RAG\n",
        "# -------------------------\n",
        "# wrap the pipeline into a LangChain LLM wrapper\n",
        "llm_hf = HuggingFacePipeline(pipeline=gen_pipe)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=(\n",
        "        \"You are a data expert. Use ONLY the provided CSV context to answer the question. \"\n",
        "        \"If the context does not contain the answer, say you are not sure.\\n\\n\"\n",
        "        \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "    ),\n",
        ")\n",
        "qa_chain = LLMChain(llm=llm_hf, prompt=prompt)\n",
        "\n",
        "class RAGState(TypedDict):\n",
        "    question: str\n",
        "    context: str\n",
        "    answer: str\n",
        "    attempt: int\n",
        "\n",
        "def retrieve_node(state: RAGState) -> RAGState:\n",
        "    q = state[\"question\"]\n",
        "    # get top-k docs (k adjustable)\n",
        "    results = lc_faiss.similarity_search(q, k=6)\n",
        "    context = \"\\n\".join([doc.page_content for doc in results])\n",
        "    return {\"question\": q, \"context\": context, \"answer\": \"\", \"attempt\": 0}\n",
        "\n",
        "def filter_node(state: RAGState) -> RAGState:\n",
        "    # If question contains a year (e.g., 2015) filter context lines to that year\n",
        "    years = re.findall(r\"\\b(19|20)\\d{2}\\b\", state[\"question\"])\n",
        "    if years:\n",
        "        # extract full year strings from question\n",
        "        matched_years = re.findall(r\"\\b(19|20)\\d{2}\\b\", state[\"question\"])\n",
        "        # matched_years returns list of captured groups; re-run to get full\n",
        "        matches_full = re.findall(r\"\\b(?:19|20)\\d{2}\\b\", state[\"question\"])\n",
        "        if matches_full:\n",
        "            filtered = [line for line in state[\"context\"].split(\"\\n\") if any(year in line for year in matches_full)]\n",
        "            if filtered:\n",
        "                return {**state, \"context\": \"\\n\".join(filtered)}\n",
        "    return state\n",
        "\n",
        "def reason_node(state: RAGState) -> RAGState:\n",
        "    ans = qa_chain.run(context=state[\"context\"], question=state[\"question\"])\n",
        "    return {**state, \"answer\": ans}\n",
        "\n",
        "def reflect_node(state: RAGState) -> RAGState:\n",
        "    # Simple reflection: if question asked for a year and answer doesn't mention it,\n",
        "    # attempt one retry with a more explicit instruction.\n",
        "    years = re.findall(r\"\\b(?:19|20)\\d{2}\\b\", state[\"question\"])\n",
        "    if years and state.get(\"attempt\", 0) < 1 and not any(y in state[\"answer\"] for y in years):\n",
        "        refl_prompt = PromptTemplate(\n",
        "            input_variables=[\"context\", \"question\", \"prev_answer\"],\n",
        "            template=(\n",
        "                \"Previous answer:\\n{prev_answer}\\n\\n\"\n",
        "                \"Using the same context below, re-check the answer and correct it such that the final answer \"\n",
        "                \"explicitly references the requested year if the data supports it. If not supported, say 'not enough data'.\\n\\n\"\n",
        "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nRevised Answer:\"\n",
        "            )\n",
        "        )\n",
        "        refl_chain = LLMChain(llm=llm_hf, prompt=refl_prompt)\n",
        "        revised = refl_chain.run(context=state[\"context\"], question=state[\"question\"], prev_answer=state[\"answer\"])\n",
        "        return {**state, \"answer\": revised, \"attempt\": state.get(\"attempt\", 0) + 1}\n",
        "    return state\n",
        "\n",
        "def output_node(state: RAGState) -> RAGState:\n",
        "    print(\"\\n🧠 Retrieved context (snippet):\\n\", (state[\"context\"][:1000] + \"...\") if len(state[\"context\"])>1000 else state[\"context\"])\n",
        "    print(\"\\n💬 Final Answer:\\n\", state[\"answer\"])\n",
        "    return state\n",
        "\n",
        "# Build the StateGraph\n",
        "graph = StateGraph(RAGState)\n",
        "graph.add_node(\"Retriever\", retrieve_node)\n",
        "graph.add_node(\"Filter\", filter_node)\n",
        "graph.add_node(\"Reasoner\", reason_node)\n",
        "graph.add_node(\"Reflector\", reflect_node)\n",
        "graph.add_node(\"Output\", output_node)\n",
        "\n",
        "graph.add_edge(START, \"Retriever\")\n",
        "graph.add_edge(\"Retriever\", \"Filter\")\n",
        "graph.add_edge(\"Filter\", \"Reasoner\")\n",
        "graph.add_edge(\"Reasoner\", \"Reflector\")\n",
        "graph.add_edge(\"Reflector\", \"Output\")\n",
        "graph.add_edge(\"Output\", END)\n",
        "\n",
        "rag_agent = graph.compile()\n",
        "print(\"✅ LangGraph RAG agent compiled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDTV1YnGXwY",
        "outputId": "9e53ba8c-43ec-4c0b-c328-9bf4e2c039ec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LangGraph RAG agent compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 9) Run queries & save artifacts\n",
        "# -------------------------\n",
        "queries = [\n",
        "    \"What is the main cause of accidents in 2015?\",\n",
        "    \"List the cause and place of accident for case_number 23.\",\n",
        "    \"Which place has the most fatalities?\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"QUERY:\", q)\n",
        "    rag_agent.invoke({\"question\": q, \"context\": \"\", \"answer\": \"\", \"attempt\": 0})\n",
        "\n",
        "# Save FAISS index and docs for reuse\n",
        "# Try to save raw index if available\n",
        "if raw_index is not None:\n",
        "    index_path = os.path.join(FINETUNE_DIR, \"faiss.index\")\n",
        "    faiss.write_index(raw_index, index_path)\n",
        "    print(\"✅ Saved raw FAISS index to\", index_path)\n",
        "# Save docs JSON (rows -> texts)\n",
        "docs_path = os.path.join(FINETUNE_DIR, \"docs.json\")\n",
        "with open(docs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(docs, f, ensure_ascii=False, indent=2)\n",
        "print(\"✅ Saved docs to\", docs_path)\n",
        "\n",
        "print(\"All done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mutUr6nKGdBf",
        "outputId": "9c2b2792-24da-43de-c836-c3979bcc0631"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUERY: What is the main cause of accidents in 2015?\n",
            "\n",
            "🧠 Retrieved context (snippet):\n",
            " input_text: 25.0 | target_text: On 25 February 2015 at Billi Markundi Stone mine (Sonebhadra, Uttar Pradesh), a Labour, Anita Kumari (22 F), was fatally strangulated when her scarf got entangled in an unguarded compressor belt-drive. The accident was in contravention of Regulations 174(2) & (5) (regarding fencing of machinery) and 34(7)(a) (regarding mine management) of the Metalliferous Mines Regulations, 1961.\n",
            "input_text: 38.0 | target_text: On 18 December 2015 at Geleki Production Oil Mine (Sibsagar, Assam), a Scrapper Mazdoor, Kanak Hatimuria (40 M), was fatally injured after losing his balance and falling 3.5m onto an iron gas pipe. The accident was in contravention of OMR 84 regulations (Reg. 18(3), (98)) and OMR' 84 regulations (Reg. 16(1), 27, 87, 88) regarding safe operations and personal protective equipment.\n",
            "input_text: 35.0 | target_text: On 07 July 2015 at Agaria Marble Mine (Rajsamand, Rajasthan), a General Mazdoor, Chogga Kumawat (50 M), was fatally injured after slippin...\n",
            "\n",
            "💬 Final Answer:\n",
            " a General Mazdoor, G.Ratish (38 M), was fatally injured after slipping and falling 30m from a bench edge\n",
            "\n",
            "============================================================\n",
            "QUERY: List the cause and place of accident for case_number 23.\n",
            "\n",
            "🧠 Retrieved context (snippet):\n",
            " input_text: 33.0 | target_text: On 23 April 2015 at Nizarna Marble Mine (Rajsamand, Rajasthan), a General Mazdoor, Ramlal (26 M), was fatally injured after slipping and falling 6m from the second bench to the quarry bed. The accident was in contravention of Section 18(4) of the Mines Act, 1952, Regulation 181, and Regulation 34 of the Metalliferous Mines Regulation, 1961, regarding safety equipment and management.\n",
            "input_text: 12.0 | target_text: On 07 January 2015 at Jhanjhar Marble Mine (Rajsamand, Rajasthan), a Mazdoor, T. Lahrilal (22 M), was fatally injured when he was hit by a dumper that was reversing. The accident was in contravention of Regulation 106(2)(b) of the Metalliferous Mines Regulations, 1961 (regarding reversing) and Section 17(1) of the Mines Act, 1952 (regarding mine management).\n",
            "input_text: 25.0 | target_text: On 25 February 2015 at Billi Markundi Stone mine (Sonebhadra, Uttar Pradesh), a Labour, Anita Kumari (22 F), was fatally strangulated when her scarf got enta...\n",
            "\n",
            "💬 Final Answer:\n",
            " Chandrika Granite Mine (Prakasham, Andhra Pradesh).\n",
            "\n",
            "============================================================\n",
            "QUERY: Which place has the most fatalities?\n",
            "\n",
            "🧠 Retrieved context (snippet):\n",
            " input_text: 34.0 | target_text: On 22 May 2015 at Sethurayanpudur Limestone Mine (Tirunelveli, Tamilnadu), a General Mazdoor, G.Ratish (38 M), was fatally injured after slipping and falling 30m from a bench edge. The accident was in contravention of Regulations 114(2), 118(4) (regarding safety appliances) and 34 (regarding management) of the Metalliferous Mines Regulations, 1961.\n",
            "input_text: 45.0 | target_text: On 28 September 2015 at Chandrika Granite Mine (Prakasham, Andhra Pradesh), a General Mazdoor, A.Raju (35 M), drowned after slipping and falling into a submerged bench. The accident was in contravention of Regulations 47(1)(b), 114, and 181 of the Metalliferous Mines Regulation 1961, as precautions like a lifeline were not used.\n",
            "input_text: 23.0 | target_text: On 11 June 2015 at Meghatuburu Iron Ore Mine (West Singhbhum, Jharkhand), a Sampler, Dipnarayan Mahato (56 M), was fatally injured when hit by a reversing light vehicle. The incident, which contravened Regulation 181 of th...\n",
            "\n",
            "💬 Final Answer:\n",
            " Sohagpur West, East & Sonhat CBM Wells (Shahdol, Madhya Pradesh)\n",
            "✅ Saved raw FAISS index to ./finetuned_flan_csv/faiss.index\n",
            "✅ Saved docs to ./finetuned_flan_csv/docs.json\n",
            "All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pk2RNeNIG4XY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}